# Website Scraping Module

–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è scraping —Å–∞–π—Ç–æ–≤ —Å –≥–∏–±–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π.

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
modules/scraping/
‚îú‚îÄ‚îÄ lib/                      # –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ http_utils.py        # HTTP client —Å retry
‚îÇ   ‚îú‚îÄ‚îÄ text_utils.py        # HTML ‚Üí —Ç–µ–∫—Å—Ç, email extraction
‚îÇ   ‚îî‚îÄ‚îÄ stats_tracker.py     # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –±–µ–Ω—á–º–∞—Ä–∫–∏
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ website_scraper.py   # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π scraper
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ BENCHMARKS.md        # –ë–µ–Ω—á–º–∞—Ä–∫–∏ –∏ time estimates
‚îÇ
‚îî‚îÄ‚îÄ results/                  # Output —Ñ–∞–π–ª—ã
```

---

## üöÄ Quick Start

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install requests beautifulsoup4 pandas
```

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```bash
# Standard scraping (—Å emails)
python modules/scraping/scripts/website_scraper.py \
    --input leads.csv \
    --output results.csv \
    --mode standard

# –†–µ–∑—É–ª—å—Ç–∞—Ç: CSV —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ [url, status, emails, phones, content]
```

---

## üéØ –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã

| –†–µ–∂–∏–º | –°–∫–æ—Ä–æ—Å—Ç—å | –ß—Ç–æ –¥–µ–ª–∞–µ—Ç | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ |
|-------|----------|-----------|---------------|
| **quick** | ‚ö°‚ö°‚ö° –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ | –¢–æ–ª—å–∫–æ detection static/dynamic | –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∞–π—Ç–æ–≤ |
| **standard** | ‚ö°‚ö° –ë—ã—Å—Ç—Ä–æ | Scraping + emails/phones | –ö–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è outreach |
| **full** | ‚ö° –ú–µ–¥–ª–µ–Ω–Ω–æ | Scraping + AI analysis | –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è |

---

## üìñ –ü—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∞–π—Ç–æ–≤

```bash
python modules/scraping/scripts/website_scraper.py \
    --input 10000_urls.csv \
    --output checked.csv \
    --mode quick \
    --workers 100

# –í—Ä–µ–º—è: ~8 –º–∏–Ω—É—Ç –¥–ª—è 10,000 —Å–∞–π—Ç–æ–≤
```

### –ü—Ä–∏–º–µ—Ä 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤

```bash
python modules/scraping/scripts/website_scraper.py \
    --input hvac_companies.csv \
    --output hvac_with_contacts.csv \
    --mode standard \
    --workers 25

# –í—Ä–µ–º—è: ~8 –º–∏–Ω—É—Ç –¥–ª—è 1,000 —Å–∞–π—Ç–æ–≤
```

### –ü—Ä–∏–º–µ—Ä 3: –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```bash
python modules/scraping/scripts/website_scraper.py \
    --input leads.csv \
    --output results.csv \
    --check-static \
    --extract-emails \
    --scrape-mode smart \
    --workers 50 \
    --timeout 20
```

---

## üìä Output —Ñ–æ—Ä–º–∞—Ç

–û–¥–∏–Ω CSV —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:

```csv
url,status,site_type,emails,phones,content,processing_time
https://example.com,success,static,contact@example.com,123-456-7890,"Company info...",0.523
https://example2.com,dynamic,dynamic,,,Low content detected,0.102
https://example3.com,timeout,,,,,15.001
```

**–ö–æ–ª–æ–Ω–∫–∏:**
- `url` - –∏—Å—Ö–æ–¥–Ω—ã–π URL
- `status` - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (success/timeout/dynamic/error)
- `site_type` - —Ç–∏–ø —Å–∞–π—Ç–∞ (static/dynamic)
- `emails` - –Ω–∞–π–¥–µ–Ω–Ω—ã–µ email –∞–¥—Ä–µ—Å–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
- `phones` - –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã
- `content` - –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–∞–π—Ç–∞
- `processing_time` - –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å–µ–∫—É–Ω–¥—ã)

**–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:**

```python
import pandas as pd

df = pd.read_csv('results.csv')

# –¢–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ
success = df[df['status'] == 'success']

# –¢–æ–ª—å–∫–æ —Å emails
with_emails = df[df['emails'].notna() & (df['emails'] != '')]

# –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å–∞–π—Ç—ã (–¥–ª—è Firecrawl)
dynamic = df[df['status'] == 'dynamic']
```

---

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

### –û—Å–Ω–æ–≤–Ω—ã–µ

- `--input FILE` - –≤—Ö–æ–¥–Ω–æ–π CSV —Å URL'–∞–º–∏ (**–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ**)
- `--output FILE` - –≤—ã—Ö–æ–¥–Ω–æ–π CSV (**–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ**)
- `--mode {quick|standard|full}` - —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã

### –§–ª–∞–≥–∏ (–¥–ª—è –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)

- `--check-static` - –ø—Ä–æ–≤–µ—Ä—è—Ç—å static/dynamic
- `--extract-emails` - –∏–∑–≤–ª–µ–∫–∞—Ç—å emails
- `--extract-phones` - –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω—ã
- `--scrape-mode {single|smart|all}` - —Ä–µ–∂–∏–º scraping —Å—Ç—Ä–∞–Ω–∏—Ü
- `--ai-analysis` - –∑–∞–ø—É—Å—Ç–∏—Ç—å AI –∞–Ω–∞–ª–∏–∑

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- `--workers N` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ (default: 25)
- `--timeout N` - HTTP timeout –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (default: 15)
- `--max-text-length N` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (default: 15000)

### –£—Ç–∏–ª–∏—Ç—ã

- `--estimate-only` - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ—Ü–µ–Ω–∫—É –≤—Ä–µ–º–µ–Ω–∏ (–Ω–µ –∑–∞–ø—É—Å–∫–∞—Ç—å scraping)

---

## üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:

```
================================================================================
EXECUTION SUMMARY
================================================================================
Total items:           1000
Completed:             1000
Success:               720 (72.0%)
Failed:                280 (28.0%)

Duration:              8.2 min (492 sec)
Speed:                 2.03 items/sec
Parallel workers:      25

Processing times:
  Average:             0.485 sec
  Min:                 0.102 sec
  Max:                 15.001 sec

Results by status:
  success                 720 ( 72.0%)
  dynamic                 180 ( 18.0%)
  timeout                  70 (  7.0%)
  connection_error         30 (  3.0%)
================================================================================

OPTIMIZATION RECOMMENDATIONS:
  1. HIGH TIMEOUTS (70): Consider increasing --timeout parameter
  2. MANY DYNAMIC SITES (180): Consider using --use-firecrawl for better coverage
```

---

## üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ status

–ü–æ—Å–ª–µ scraping –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:

```python
import pandas as pd

df = pd.read_csv('results.csv')

# –£—Å–ø–µ—à–Ω—ã–µ ‚Üí –≥–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
success = df[df['status'] == 'success']
success.to_csv('ready_to_use.csv', index=False)

# –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ ‚Üí –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ Firecrawl
dynamic = df[df['status'] == 'dynamic']
dynamic.to_csv('process_with_firecrawl.csv', index=False)

# –¢–∞–π–º–∞—É—Ç—ã ‚Üí retry —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º timeout
timeouts = df[df['status'] == 'timeout']
timeouts.to_csv('retry_with_higher_timeout.csv', index=False)
```

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- **[BENCHMARKS.md](docs/BENCHMARKS.md)** - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ –∏ time estimates
- **[API Documentation](lib/)** - –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫

---

## üí° Best Practices

1. **–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å quick mode** –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
2. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --estimate-only** –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
3. **–†–∞–∑–±–∏–≤–∞–π—Ç–µ –±–æ–ª—å—à–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –±–∞—Ç—á–∏** (<2000 —Å–∞–π—Ç–æ–≤ –∑–∞ —Ä–∞–∑)
4. **–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
5. **–§–∏–ª—å—Ç—Ä—É–π—Ç–µ –ø–æ status** –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤

---

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–Ω–æ–≥–æ timeout'–æ–≤ (>10%)
**–†–µ—à–µ–Ω–∏–µ:** –£–≤–µ–ª–∏—á—å—Ç–µ `--timeout 30` –∏–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ `--workers 15`

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–Ω–æ–≥–æ dynamic sites (>20%)
**–†–µ—à–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Firecrawl –¥–ª—è fallback –æ–±—Ä–∞–±–æ—Ç–∫–∏

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–∏–∑–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å (<5 items/sec)
**–†–µ—à–µ–Ω–∏–µ:** –£–≤–µ–ª–∏—á—å—Ç–µ `--workers 50` (–µ—Å–ª–∏ –Ω–µ—Ç rate limiting)

### –ü—Ä–æ–±–ª–µ–º–∞: HTTP 429 errors (rate limiting)
**–†–µ—à–µ–Ω–∏–µ:** –£–º–µ–Ω—å—à–∏—Ç–µ `--workers 10` –∏ –¥–æ–±–∞–≤—å—Ç–µ delay

---

## üìû Support

–ï—Å–ª–∏ –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã - —Å–º–æ—Ç—Ä–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤ `docs/BENCHMARKS.md` –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–≤—Ç–æ—Ä—É.
