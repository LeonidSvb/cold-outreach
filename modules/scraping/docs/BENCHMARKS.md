# Website Scraper - Benchmarks –∏ Time Estimates

> –†–µ–∞–ª—å–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è scraping –∑–∞–¥–∞—á

---

## üìä –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (25 workers)

| –†–µ–∂–∏–º | –û–ø–µ—Ä–∞—Ü–∏–∏ | –í—Ä–µ–º—è –Ω–∞ 1 —Å–∞–π—Ç | 100 —Å–∞–π—Ç–æ–≤ | 1,000 —Å–∞–π—Ç–æ–≤ | 10,000 —Å–∞–π—Ç–æ–≤ |
|-------|----------|-----------------|------------|--------------|---------------|
| **quick** | Static/Dynamic detection | ~0.05 —Å–µ–∫ | ~5 —Å–µ–∫ | ~50 —Å–µ–∫ | ~8 –º–∏–Ω |
| **standard** | Scraping + Emails | ~0.5 —Å–µ–∫ | ~50 —Å–µ–∫ | ~8 –º–∏–Ω | ~80 –º–∏–Ω |
| **full** | Scraping + AI | ~3.0 —Å–µ–∫ | ~5 –º–∏–Ω | ~50 –º–∏–Ω | ~8 —á–∞—Å–æ–≤ |

---

## üîß –í–ª–∏—è–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### Workers (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ø–æ—Ç–æ–∫–∏)

| Workers | 100 —Å–∞–π—Ç–æ–≤ (standard) | 1,000 —Å–∞–π—Ç–æ–≤ (standard) | 10,000 —Å–∞–π—Ç–æ–≤ (standard) |
|---------|----------------------|-------------------------|--------------------------|
| 10 | ~2 –º–∏–Ω | ~20 –º–∏–Ω | ~3.3 —á–∞—Å–∞ |
| 25 | ~50 —Å–µ–∫ | ~8 –º–∏–Ω | ~80 –º–∏–Ω |
| 50 | ~25 —Å–µ–∫ | ~4 –º–∏–Ω | ~40 –º–∏–Ω |
| 100 | ~15 —Å–µ–∫ | ~2.5 –º–∏–Ω | ~25 –º–∏–Ω |

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**
- **10-25 workers** - —Å—Ç–∞–±–∏–ª—å–Ω–æ, –Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫ rate limiting
- **50 workers** - –±—ã—Å—Ç—Ä–æ, –Ω–æ –≤–æ–∑–º–æ–∂–Ω—ã timeout'—ã –Ω–∞ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–∞–π—Ç–∞—Ö
- **100+ workers** - –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ, –Ω–æ –≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫

---

## üéØ –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã

### Mode: `quick`
**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- HTTP –∑–∞–ø—Ä–æ—Å –∫ homepage
- –ü—Ä–æ–≤–µ—Ä–∫–∞ static/dynamic
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ status

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –ù—É–∂–Ω–æ –±—ã—Å—Ç—Ä–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å 10,000+ —Å–∞–π—Ç–æ–≤
- –ü–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å dynamic —Å–∞–π—Ç—ã –¥–ª—è Firecrawl
- –ù—É–∂–Ω–∞ —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è URL'–æ–≤

**–ü—Ä–∏–º–µ—Ä:**
```bash
python website_scraper.py --input 10000_urls.csv --output checked.csv --mode quick --workers 100
# –í—Ä–µ–º—è: ~8 –º–∏–Ω—É—Ç
# –†–µ–∑—É–ª—å—Ç–∞—Ç: CSV —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ [url, status, site_type]
```

---

### Mode: `standard`
**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- HTTP –∑–∞–ø—Ä–æ—Å –∫ homepage + –≤–∞–∂–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (/contact, /about)
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ emails
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
- –û—á–∏—Å—Ç–∫–∞ HTML ‚Üí —Ç–µ–∫—Å—Ç

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –ù—É–∂–Ω—ã –∫–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è cold outreach
- –ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è AI –∞–Ω–∞–ª–∏–∑ (—ç–∫–æ–Ω–æ–º–∏—è $$$)
- –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ use cases

**–ü—Ä–∏–º–µ—Ä:**
```bash
python website_scraper.py --input 1000_hvac.csv --output hvac_contacts.csv --mode standard --workers 25
# –í—Ä–µ–º—è: ~8 –º–∏–Ω—É—Ç
# –†–µ–∑—É–ª—å—Ç–∞—Ç: CSV —Å [url, status, emails, phones, content]
```

---

### Mode: `full`
**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –í—Å—ë –∏–∑ `standard` —Ä–µ–∂–∏–º–∞
- AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (personalization, ICP validation, etc)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è structured data

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –ù—É–∂–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è outreach
- ICP validation
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–∞–Ω–∏–π

**–ü—Ä–∏–º–µ—Ä:**
```bash
python website_scraper.py --input 100_prospects.csv --output enriched.csv --mode full --workers 10
# –í—Ä–µ–º—è: ~5 –º–∏–Ω—É—Ç
# –°—Ç–æ–∏–º–æ—Å—Ç—å AI: ~$0.10 (OpenAI gpt-4o-mini)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: CSV —Å [url, emails, ai_summary, personalization_hook, owner_name, etc]
```

---

## üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å AI –∞–Ω–∞–ª–∏–∑–∞

**OpenAI gpt-4o-mini** (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):
- Input: $0.150 / 1M tokens
- Output: $0.600 / 1M tokens

**–†–∞—Å—á—ë—Ç:**
- 1 —Å–∞–π—Ç ‚âà 5,000 tokens input + 500 tokens output
- 1 —Å–∞–π—Ç ‚âà $0.001 (–æ–¥–Ω–∞ –¥–µ—Å—è—Ç–∞—è —Ü–µ–Ω—Ç–∞)
- 1,000 —Å–∞–π—Ç–æ–≤ ‚âà **$1.00**
- 10,000 —Å–∞–π—Ç–æ–≤ ‚âà **$10.00**

**OpenAI gpt-4o** (–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π):
- Input: $2.50 / 1M tokens
- Output: $10.00 / 1M tokens
- 1,000 —Å–∞–π—Ç–æ–≤ ‚âà **$15.00**

---

## üìà –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

| –ü—Ä–æ–±–ª–µ–º–∞ | –°–∏–º–ø—Ç–æ–º | –†–µ—à–µ–Ω–∏–µ |
|----------|---------|---------|
| **–ú–Ω–æ–≥–æ timeout'–æ–≤** | >10% status=timeout | –£–≤–µ–ª–∏—á–∏—Ç—å `--timeout 30` |
| **–ú–Ω–æ–≥–æ dynamic sites** | >20% status=dynamic | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Firecrawl –¥–ª—è fallback |
| **–ú–µ–¥–ª–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å** | <5 items/sec | –£–≤–µ–ª–∏—á–∏—Ç—å `--workers 50` |
| **–ú–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ 429** | status=http_error_429 | –£–º–µ–Ω—å—à–∏—Ç—å workers, –¥–æ–±–∞–≤–∏—Ç—å delay |

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**–î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (100 —Å–∞–π—Ç–æ–≤):**
```bash
--mode quick --workers 50 --timeout 10
# –í—Ä–µ–º—è: ~10 —Å–µ–∫—É–Ω–¥
```

**–î–ª—è production (1,000+ —Å–∞–π—Ç–æ–≤):**
```bash
--mode standard --workers 25 --timeout 15
# –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
```

**–î–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ enrichment (AI):**
```bash
--mode full --workers 10 --timeout 20 --max-text-length 15000
# –ú–µ–Ω—å—à–µ workers = –º–µ–Ω—å—à–µ rate limiting –æ—Ç OpenAI
```

---

## üß™ –¢–µ—Å—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### Test 1: HVAC –∫–æ–º–ø–∞–Ω–∏–∏ –≤ –¢–µ—Ö–∞—Å–µ
```
Input:     1,000 HVAC —Å–∞–π—Ç–æ–≤
Mode:      standard
Workers:   25
Duration:  8.2 –º–∏–Ω—É—Ç—ã
Results:
  - Success:       720 (72%)
  - Dynamic:       180 (18%)
  - Timeout:        70 (7%)
  - Other errors:   30 (3%)
  - Emails found:  580 (58%)
```

### Test 2: Random B2B websites
```
Input:     500 B2B —Å–∞–π—Ç–æ–≤
Mode:      full (—Å AI)
Workers:   10
Duration:  25 –º–∏–Ω—É—Ç
AI Cost:   $0.52
Results:
  - Success:       420 (84%)
  - Dynamic:        50 (10%)
  - Failures:       30 (6%)
  - AI analysis:   420/420 (100%)
  - Owner names:   280 (67% of analyzed)
```

---

## üìù –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ `--estimate-only` –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏:

```bash
python website_scraper.py --input huge_list.csv --output results.csv --mode standard --estimate-only

# Output:
# ================================================================================
# UNIVERSAL WEBSITE SCRAPER
# ================================================================================
# Input file:        huge_list.csv
# Total URLs:        10,000
# Mode:              standard
# Workers:           25
#
# Estimated time:    80.0 min (4800 sec)
# ================================================================================
# Estimation only mode - exiting without scraping.
```

---

## üéØ –í—ã–±–æ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### –í–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è:

1. **–°–∫–æ–ª—å–∫–æ —É –º–µ–Ω—è —Å–∞–π—Ç–æ–≤?**
   - <100 ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `--workers 50` –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
   - 100-1000 ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `--workers 25` (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)
   - >1000 ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `--workers 25`, –Ω–æ —Ä–∞–∑–±–µ–π—Ç–µ –Ω–∞ –±–∞—Ç—á–∏

2. **–ù—É–∂–µ–Ω –ª–∏ –º–Ω–µ AI –∞–Ω–∞–ª–∏–∑?**
   - –î–∞ ‚Üí `--mode full` (–¥–æ—Ä–æ–∂–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ)
   - –ù–µ—Ç ‚Üí `--mode standard` (–±—ã—Å—Ç—Ä–æ, –±–µ—Å–ø–ª–∞—Ç–Ω–æ)

3. **–ö–∞–∫–æ–π —É –º–µ–Ω—è budget –≤—Ä–µ–º–µ–Ω–∏?**
   - <5 –º–∏–Ω—É—Ç ‚Üí `--mode quick`
   - <30 –º–∏–Ω—É—Ç ‚Üí `--mode standard` (<2000 —Å–∞–π—Ç–æ–≤)
   - –ù–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ ‚Üí `--mode full` (–ª—é–±–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)

4. **–ö–∞–∫–æ–π success rate –º–Ω–µ –Ω—É–∂–µ–Ω?**
   - >90% ‚Üí –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Firecrawl fallback –¥–ª—è dynamic sites
   - 70-80% ‚Üí Standard HTTP scraping –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ

---

## üîÑ Workflow –ø—Ä–∏–º–µ—Ä—ã

### Workflow 1: –ë—ã—Å—Ç—Ä–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑

```bash
# –®–∞–≥ 1: –ë—ã—Å—Ç—Ä–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å 10,000 —Å–∞–π—Ç–æ–≤ (8 –º–∏–Ω)
python website_scraper.py --input all_sites.csv --output checked.csv --mode quick --workers 100

# –®–∞–≥ 2: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ static —Å–∞–π—Ç—ã
# (–≤ Python/pandas)
df = pd.read_csv('checked.csv')
static_sites = df[df['site_type'] == 'static']
static_sites.to_csv('static_only.csv')

# –®–∞–≥ 3: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ static —Å–∞–π—Ç–æ–≤ (20 –º–∏–Ω)
python website_scraper.py --input static_only.csv --output enriched.csv --mode full --workers 10
```

### Workflow 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å fallback

```bash
# –®–∞–≥ 1: Standard scraping (8 –º–∏–Ω)
python website_scraper.py --input leads.csv --output results.csv --mode standard --workers 25

# –®–∞–≥ 2: –í—ã—Ç–∞—â–∏—Ç—å dynamic sites –¥–ª—è Firecrawl
df = pd.read_csv('results.csv')
dynamic = df[df['status'] == 'dynamic']
dynamic.to_csv('dynamic_sites.csv')

# –®–∞–≥ 3: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å dynamic —á–µ—Ä–µ–∑ Firecrawl (–æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç)
# python firecrawl_scraper.py --input dynamic_sites.csv --output firecrawl_results.csv

# –®–∞–≥ 4: –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
```

---

## ‚ö° Quick Reference

```bash
# –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π —Å–ø–æ—Å–æ–± (—Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞)
--mode quick --workers 100

# –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å (scraping + emails)
--mode standard --workers 25

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (—Å AI)
--mode full --workers 10

# –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
--check-static --extract-emails --scrape-mode smart --workers 50
```
